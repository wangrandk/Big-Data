{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ad-hoc computations with Futures\n",
    "------------------------------------\n",
    "\n",
    "While many parallel applications can be described as maps, some can be more complex.\n",
    "In this section we look at the asynchronous Future interface,\n",
    "which provides a simple API for ad-hoc parallelism.\n",
    "This is useful for when your computations don't fit a regular pattern.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "*  Use the `concurrent.futures` function `submit` to perform ad-hoc parallel computing\n",
    "\n",
    "### Requirements\n",
    "\n",
    "*  Pandas\n",
    "*  concurrent.futures (standard in Python 3, `pip install futures` in Python 2)\n",
    "\n",
    "\n",
    "    pip install snakeviz\n",
    "    pip install futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application\n",
    "\n",
    "Given our HDF5 files from the last section we want to find the two datasets with the greatest pair-wise correlation.  This forces us to consider all $n\\times(n-1)$ possibilities.\n",
    "\n",
    "As before we start with a sequential solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "filenames = sorted(glob(os.path.join('..', 'data', 'json', '*.h5')))  # ../data/json/*.json\n",
    "filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "series = {}\n",
    "for fn in filenames:\n",
    "    series[fn] = pd.read_hdf(fn)['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = {}\n",
    "\n",
    "for a in filenames:\n",
    "    for b in filenames:\n",
    "        if a != b:\n",
    "            results[a, b] = series[a].corr(series[b])\n",
    "            \n",
    "((a, b), corr) = max(results.items(), key=lambda kv: kv[1])\n",
    "print(\"%s matches with %s with correlation %f\" % (a, b, corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visually inspect correlated series\n",
    "\n",
    "We use matplotlib to visually inspect the highly correlated timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(series[a] / series[a].max())\n",
    "plt.plot(series[b] / series[b].max())\n",
    "plt.xticks(visible=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "This computation starts out with an embarrassingly parallel part loading data from disk:\n",
    "\n",
    "```python\n",
    "series = {}\n",
    "for fn in filenames:\n",
    "    series[fn] = pd.read_hdf(fn)['x']\n",
    "```\n",
    "\n",
    "It follows with a doubly nested for loop with an if statement.  \n",
    "\n",
    "```python\n",
    "results = {}\n",
    "\n",
    "for a in filenames:\n",
    "    for b in filenames:\n",
    "        if a != b:\n",
    "            results[a, b] = series[a].corr(series[b])\n",
    "```\n",
    "\n",
    "It *is* possible to solve this problem with `map`, but it requires some cleverness.  Instead we'll learn `submit`, an interface to start individual function calls asynchronously.\n",
    "\n",
    "It finishes with a reduction on small data.  We're not going to care about parallelizing this (it's already very fast.)\n",
    "\n",
    "```python\n",
    "((a, b), corr) = max(results.items(), key=lambda kv: kv[1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executor.submit\n",
    "\n",
    "The `submit` method starts a computation in a separate thread or process and immediately gives us a `Future` object that refers to the result.  At first, the future is pending.  Once the function completes the future is finished. \n",
    "\n",
    "We collect the result of the task with the `.result()` method,\n",
    "which does not return until the results are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "e = ThreadPoolExecutor(4)\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "def slowadd(a, b, delay=1):\n",
    "    sleep(delay)\n",
    "    return a + b\n",
    "\n",
    "future = e.submit(slowadd, 1, 2)\n",
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit many tasks, receive many futures\n",
    "\n",
    "Because submit returns immediately we can submit many tasks all at once and they will execute in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results = [slowadd(i, i, delay=1) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "futures = [e.submit(slowadd, 1, 1, delay=1) for i in range(10)]\n",
    "results = [f.result() for f in futures]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit different tasks\n",
    "\n",
    "The virtue of submit is that you can submit different functions and you can perform a bit of logic on each input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: parallelize the following code with e.submit\n",
    "\n",
    "1.  Replace the `results` list with a list called `futures`\n",
    "2.  Replace calls to `slowadd` and `slowinc` with `e.submit` calls on those functions\n",
    "3.  At the end, block on the computation by recreating the `results` list by calling `.result()` on each future in the `futures` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Sequential Version\n",
    "\n",
    "def slowadd(a, b, delay=1):\n",
    "    sleep(delay)\n",
    "    return a + b\n",
    "\n",
    "def slowsub(a, b, delay=1):\n",
    "    sleep(delay)\n",
    "    return a - b\n",
    "\n",
    "results = []\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if i < j:\n",
    "            results.append(slowadd(i, j, delay=1))\n",
    "        elif i > j:\n",
    "            results.append(slowsub(i, j, delay=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Parallel Version\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load solutions/submit-1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion on submit\n",
    "\n",
    "*  Submit fires off a single function call in the background, returning a future.  \n",
    "*  When we combine submit with a single for loop we recover the functionality of map.  \n",
    "*  When we want to collect our results we replace each of our futures, `f`, with a call to `f.result()`\n",
    "*  We can combine submit with multiple for loops and other general programming to get something more general than map.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Parallelize pair-wise correlations with `e.submit`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Sequential Code\n",
    "\n",
    "results = {}\n",
    "\n",
    "for a in filenames:\n",
    "    for b in filenames:\n",
    "        if a != b:\n",
    "            results[a, b] = series[a].corr(series[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "### Parallel Code\n",
    "\n",
    "futures = ... # TODO\n",
    "\n",
    "# TODO\n",
    "\n",
    "results = ... # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load solutions/submit-2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Threads vs Processes\n",
    "\n",
    "Try the exercise above using Processes vs Threads by replacing `e` with a ProcessPoolExecutor:\n",
    "\n",
    "#### Before\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "e = ThreadPoolExecutor(4)\n",
    "```\n",
    "\n",
    "#### After\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "e = ProcessPoolExecutor(4)\n",
    "```\n",
    "\n",
    "How does performance vary?  We'll talk more about the tradeoffs between threads and processes later on in the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Break Python by loading the data in parallel\n",
    "\n",
    "The HDF5 library we use to load our data is not threadsafe and can cause our entire Python session to crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "e = ThreadPoolExecutor(4)\n",
    "\n",
    "dfs = e.map(pd.read_hdf, filenames)\n",
    "series = e.map(lambda df: df['close'], dfs)\n",
    "series = dict(zip(filenames, series))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "-----------\n",
    "\n",
    "*  We learned how `e.submit` can help us to parallelize more complex applications\n",
    "*  We used `e.submit` to compute pairwise collelations in parallel\n",
    "*  We learned that this didn't actually speed up our code very much\n",
    "*  We compared threads against processes to see some performance differences\n",
    "*  We crashed our Python session by using threads with unsafe code, warning us that parallelism is sometimes dangerous"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
